"""Migration to SQLAlchemy

Revision ID: af780a5cffbe
Revises:
Create Date: 2024-11-02 11:20:14.433728

This is the initial migration after switching from dataset to SQLAlchemy.
FIXME: It should be removed when demo and prod are migrated.
Cf https://alembic.sqlalchemy.org/en/latest/cookbook.html#building-an-up-to-date-database-from-scratch

It has been generated by comparing the SQLAlchemy schema with the current database schema.

Changes are mostly:
- Text (dataset default for str) to String (SQLAlchemy default for str)
- BigInt (dataset default for int) to Integer (SQLAlchemy default for int)
- Removed duplicated columns from catalog (Dataset) in datasets_bouquets, that is now strictly a join table
- Some index removed
- Foreign keys added
"""

from typing import Sequence, Union

import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

from alembic import op

# revision identifiers, used by Alembic.
revision: str = "af780a5cffbe"
down_revision: Union[str, None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    op.alter_column(
        "bouquets", "bouquet_id", existing_type=sa.TEXT(), type_=sa.String(), nullable=False
    )
    op.alter_column("bouquets", "name", existing_type=sa.TEXT(), type_=sa.String(), nullable=False)
    op.alter_column("bouquets", "private", existing_type=sa.BOOLEAN(), nullable=False)
    op.alter_column(
        "bouquets",
        "organization",
        existing_type=sa.TEXT(),
        type_=sa.String(),
        existing_nullable=True,
    )
    op.alter_column(
        "bouquets", "owner", existing_type=sa.TEXT(), type_=sa.String(), existing_nullable=True
    )
    op.alter_column(
        "bouquets", "extras", existing_type=postgresql.JSONB(astext_type=sa.Text()), nullable=False
    )
    op.alter_column(
        "bouquets", "last_modified", existing_type=postgresql.TIMESTAMP(), nullable=False
    )
    op.alter_column("bouquets", "created_at", existing_type=postgresql.TIMESTAMP(), nullable=False)
    op.alter_column(
        "bouquets", "nb_datasets", existing_type=sa.BIGINT(), type_=sa.Integer(), nullable=False
    )
    op.alter_column(
        "bouquets", "nb_factors", existing_type=sa.BIGINT(), type_=sa.Integer(), nullable=False
    )
    op.alter_column("bouquets", "deleted", existing_type=sa.BOOLEAN(), nullable=False)
    op.drop_index("ix_bouquets_bed5dd1fed9bf1b3", table_name="bouquets")
    op.create_unique_constraint(None, "bouquets", ["bouquet_id"])
    op.alter_column(
        "catalog", "dataset_id", existing_type=sa.TEXT(), type_=sa.String(), nullable=False
    )
    op.alter_column("catalog", "title", existing_type=sa.TEXT(), type_=sa.String(), nullable=False)
    op.alter_column(
        "catalog",
        "organization",
        existing_type=sa.TEXT(),
        type_=sa.String(),
        existing_nullable=True,
    )
    op.alter_column(
        "catalog", "owner", existing_type=sa.TEXT(), type_=sa.String(), existing_nullable=True
    )
    op.alter_column(
        "catalog", "nb_resources", existing_type=sa.BIGINT(), type_=sa.Integer(), nullable=False
    )
    op.alter_column(
        "catalog", "extras", existing_type=postgresql.JSONB(astext_type=sa.Text()), nullable=False
    )
    op.alter_column(
        "catalog", "last_modified", existing_type=postgresql.TIMESTAMP(), nullable=False
    )
    op.alter_column("catalog", "created_at", existing_type=postgresql.TIMESTAMP(), nullable=False)
    op.alter_column("catalog", "private", existing_type=sa.BOOLEAN(), nullable=False)
    op.alter_column(
        "catalog", "acronym", existing_type=sa.TEXT(), type_=sa.String(), existing_nullable=True
    )
    op.alter_column("catalog", "slug", existing_type=sa.TEXT(), type_=sa.String(), nullable=False)
    op.alter_column("catalog", "deleted", existing_type=sa.BOOLEAN(), nullable=False)
    op.alter_column(
        "catalog", "description", existing_type=sa.TEXT(), type_=sa.String(), nullable=False
    )
    op.alter_column(
        "catalog", "frequency", existing_type=sa.TEXT(), type_=sa.String(), nullable=False
    )
    op.alter_column(
        "catalog", "license", existing_type=sa.TEXT(), type_=sa.String(), nullable=False
    )
    op.alter_column(
        "catalog",
        "license__title",
        existing_type=sa.TEXT(),
        type_=sa.String(),
        existing_nullable=True,
    )
    op.alter_column(
        "catalog", "quality", existing_type=postgresql.JSONB(astext_type=sa.Text()), nullable=False
    )
    op.alter_column(
        "catalog", "internal", existing_type=postgresql.JSONB(astext_type=sa.Text()), nullable=False
    )
    op.alter_column(
        "catalog",
        "harvest__backend",
        existing_type=sa.TEXT(),
        type_=sa.String(),
        existing_nullable=True,
    )
    op.alter_column(
        "catalog",
        "harvest__dct_identifier",
        existing_type=sa.TEXT(),
        type_=sa.String(),
        existing_nullable=True,
    )
    op.alter_column(
        "catalog",
        "harvest__domain",
        existing_type=sa.TEXT(),
        type_=sa.String(),
        existing_nullable=True,
    )
    op.alter_column(
        "catalog",
        "harvest__remote_id",
        existing_type=sa.TEXT(),
        type_=sa.String(),
        existing_nullable=True,
    )
    op.alter_column(
        "catalog",
        "harvest__remote_url",
        existing_type=sa.TEXT(),
        type_=sa.String(),
        existing_nullable=True,
    )
    op.alter_column(
        "catalog",
        "harvest__source_id",
        existing_type=sa.TEXT(),
        type_=sa.String(),
        existing_nullable=True,
    )
    op.alter_column(
        "catalog",
        "harvest__uri",
        existing_type=sa.TEXT(),
        type_=sa.String(),
        existing_nullable=True,
    )
    op.alter_column("catalog", "has_license", existing_type=sa.BOOLEAN(), nullable=False)
    op.alter_column(
        "catalog", "has_harvest__created_at", existing_type=sa.BOOLEAN(), nullable=False
    )
    op.alter_column(
        "catalog", "has_harvest__modified_at", existing_type=sa.BOOLEAN(), nullable=False
    )
    op.alter_column("catalog", "has_harvest__remote_id", existing_type=sa.BOOLEAN(), nullable=False)
    op.alter_column(
        "catalog", "has_harvest__remote_url", existing_type=sa.BOOLEAN(), nullable=False
    )
    op.alter_column("catalog", "has_resources__total", existing_type=sa.BOOLEAN(), nullable=False)
    op.alter_column("catalog", "has_spatial__zones", existing_type=sa.BOOLEAN(), nullable=False)
    op.alter_column("catalog", "has_spatial__geom", existing_type=sa.BOOLEAN(), nullable=False)
    op.alter_column("catalog", "has_temporal_coverage", existing_type=sa.BOOLEAN(), nullable=False)
    op.alter_column("catalog", "has_frequency", existing_type=sa.BOOLEAN(), nullable=False)
    op.alter_column("catalog", "has_contact_point", existing_type=sa.BOOLEAN(), nullable=False)
    op.alter_column(
        "catalog",
        "prefix_harvest_remote_id",
        existing_type=sa.TEXT(),
        type_=sa.String(),
        nullable=False,
    )
    op.alter_column(
        "catalog",
        "prefix_harvest_remote_url",
        existing_type=sa.TEXT(),
        type_=sa.String(),
        nullable=False,
    )
    op.alter_column(
        "catalog", "url_data_gouv", existing_type=sa.TEXT(), type_=sa.String(), nullable=False
    )
    op.alter_column("catalog", "consistent_dates", existing_type=sa.BOOLEAN(), nullable=False)
    op.alter_column(
        "catalog", "consistent_temporal_coverage", existing_type=sa.BOOLEAN(), nullable=False
    )
    op.drop_index("ix_catalog_36c1c67adb3d1dd6", table_name="catalog")
    op.create_unique_constraint(None, "catalog", ["dataset_id"])
    op.drop_column("catalog", "harvest__ckan_name")
    op.drop_column("catalog", "harvest__ckan_source")
    op.alter_column(
        "datasets_bouquets",
        "bouquet_id",
        existing_type=sa.TEXT(),
        type_=sa.String(),
        nullable=False,
    )
    op.alter_column(
        "datasets_bouquets",
        "dataset_id",
        existing_type=sa.TEXT(),
        type_=sa.String(),
        nullable=False,
    )
    op.create_foreign_key(None, "datasets_bouquets", "bouquets", ["bouquet_id"], ["bouquet_id"])
    op.create_foreign_key(None, "datasets_bouquets", "catalog", ["dataset_id"], ["dataset_id"])
    op.drop_column("datasets_bouquets", "prefix_harvest_remote_id")
    op.drop_column("datasets_bouquets", "consistent_temporal_coverage")
    op.drop_column("datasets_bouquets", "owner")
    op.drop_column("datasets_bouquets", "prefix_harvest_remote_url")
    op.drop_column("datasets_bouquets", "harvest__uri")
    op.drop_column("datasets_bouquets", "harvest__source_id")
    op.drop_column("datasets_bouquets", "harvest__remote_url")
    op.drop_column("datasets_bouquets", "license")
    op.drop_column("datasets_bouquets", "nb_resources")
    op.drop_column("datasets_bouquets", "frequency")
    op.drop_column("datasets_bouquets", "spatial")
    op.drop_column("datasets_bouquets", "deleted")
    op.drop_column("datasets_bouquets", "harvest__last_update")
    op.drop_column("datasets_bouquets", "harvest__dct_identifier")
    op.drop_column("datasets_bouquets", "slug")
    op.drop_column("datasets_bouquets", "created_at")
    op.drop_column("datasets_bouquets", "bouquet_name")
    op.drop_column("datasets_bouquets", "harvest__backend")
    op.drop_column("datasets_bouquets", "harvest__ckan_name")
    op.drop_column("datasets_bouquets", "has_spatial__zones")
    op.drop_column("datasets_bouquets", "last_modified")
    op.drop_column("datasets_bouquets", "acronym")
    op.drop_column("datasets_bouquets", "harvest__ckan_source")
    op.drop_column("datasets_bouquets", "has_frequency")
    op.drop_column("datasets_bouquets", "contact_point")
    op.drop_column("datasets_bouquets", "license__title")
    op.drop_column("datasets_bouquets", "extras")
    op.drop_column("datasets_bouquets", "has_license")
    op.drop_column("datasets_bouquets", "harvest__created_at")
    op.drop_column("datasets_bouquets", "has_harvest__remote_id")
    op.drop_column("datasets_bouquets", "harvest__domain")
    op.drop_column("datasets_bouquets", "quality")
    op.drop_column("datasets_bouquets", "private")
    op.drop_column("datasets_bouquets", "description")
    op.drop_column("datasets_bouquets", "has_contact_point")
    op.drop_column("datasets_bouquets", "consistent_dates")
    op.drop_column("datasets_bouquets", "organization")
    op.drop_column("datasets_bouquets", "has_temporal_coverage")
    op.drop_column("datasets_bouquets", "url_data_gouv")
    op.drop_column("datasets_bouquets", "harvest__modified_at")
    op.drop_column("datasets_bouquets", "has_resources__total")
    op.drop_column("datasets_bouquets", "temporal_coverage")
    op.drop_column("datasets_bouquets", "harvest__remote_id")
    op.drop_column("datasets_bouquets", "title")
    op.drop_column("datasets_bouquets", "has_harvest__modified_at")
    op.drop_column("datasets_bouquets", "has_harvest__remote_url")
    op.drop_column("datasets_bouquets", "has_harvest__created_at")
    op.drop_column("datasets_bouquets", "has_spatial__geom")
    op.drop_column("datasets_bouquets", "internal")
    op.alter_column("metrics", "date", existing_type=sa.DATE(), nullable=False)
    op.alter_column(
        "metrics", "measurement", existing_type=sa.TEXT(), type_=sa.String(), nullable=False
    )
    op.alter_column(
        "metrics", "value", existing_type=sa.DOUBLE_PRECISION(precision=53), nullable=False
    )
    op.alter_column(
        "metrics",
        "organization",
        existing_type=sa.TEXT(),
        type_=sa.String(),
        existing_nullable=True,
    )
    op.drop_index("ix_metrics_1bed118b5df511ce", table_name="metrics")
    op.alter_column(
        "organizations",
        "organization_id",
        existing_type=sa.TEXT(),
        type_=sa.String(),
        nullable=False,
    )
    op.alter_column(
        "organizations", "name", existing_type=sa.TEXT(), type_=sa.String(), nullable=False
    )
    op.alter_column(
        "organizations",
        "acronym",
        existing_type=sa.TEXT(),
        type_=sa.String(),
        existing_nullable=True,
    )
    op.alter_column("organizations", "service_public", existing_type=sa.BOOLEAN(), nullable=False)
    op.drop_index("ix_organizations_472c1f99a32def1b", table_name="organizations")
    op.create_unique_constraint(None, "organizations", ["organization_id"])
    op.alter_column(
        "resources", "resource_id", existing_type=sa.TEXT(), type_=sa.String(), nullable=False
    )
    op.alter_column(
        "resources", "title", existing_type=sa.TEXT(), type_=sa.String(), existing_nullable=True
    )
    op.alter_column(
        "resources",
        "description",
        existing_type=sa.TEXT(),
        type_=sa.String(),
        existing_nullable=True,
    )
    op.alter_column(
        "resources", "type", existing_type=sa.TEXT(), type_=sa.String(), existing_nullable=True
    )
    op.alter_column(
        "resources", "format", existing_type=sa.TEXT(), type_=sa.String(), existing_nullable=True
    )
    op.alter_column("resources", "url", existing_type=sa.TEXT(), type_=sa.String(), nullable=False)
    op.alter_column(
        "resources", "latest", existing_type=sa.TEXT(), type_=sa.String(), nullable=False
    )
    op.alter_column(
        "resources", "filesize", existing_type=sa.TEXT(), type_=sa.String(), existing_nullable=True
    )
    op.alter_column(
        "resources", "mime", existing_type=sa.TEXT(), type_=sa.String(), existing_nullable=True
    )
    op.alter_column("resources", "created_at", existing_type=postgresql.TIMESTAMP(), nullable=False)
    op.alter_column(
        "resources", "last_modified", existing_type=postgresql.TIMESTAMP(), nullable=False
    )
    op.alter_column(
        "resources",
        "internal",
        existing_type=postgresql.JSONB(astext_type=sa.Text()),
        nullable=False,
    )
    op.alter_column("resources", "title__exists", existing_type=sa.BOOLEAN(), nullable=False)
    op.alter_column(
        "resources", "dataset_id", existing_type=sa.TEXT(), type_=sa.String(), nullable=False
    )
    op.drop_index("ix_resources_e2894a5867e06ae2", table_name="resources")
    op.create_foreign_key(None, "resources", "catalog", ["dataset_id"], ["dataset_id"])
    # moved to the end, the constraint must be set before foreign key definition
    op.create_foreign_key(None, "catalog", "organizations", ["organization"], ["organization_id"])


def downgrade() -> None:
    pass
